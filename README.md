# TriminoMokAI

AlphaGo에 영감을 받아 제작된 트리미노목(TriminoMok) 게임 AI입니다. 이 AI는 몬테카를로 트리 탐색(MCTS)과 심층 신경망(Policy Network, Value Network)을 사용하여 게임을 학습하고 최적의 수를 찾습니다.

## 🎮 게임 소개: 트리미노목 (TriminoMok)

트리미노목은 19x19 바둑판 위에서 진행되는 턴제 전략 게임입니다. 플레이어는 일반적인 바둑알 대신 3개의 돌이 이어진 '트리미노' 블록을 놓습니다.

**주요 규칙:**
- **목표:** 게임 종료 시점에 더 많은 점수를 획득하는 것이 목표입니다. 5개 이상의 돌을 직선으로 연결하면 점수를 얻습니다.
- **트리미노:** 플레이어는 매 턴마다 다른 모양의 트리미노 블록을 받습니다.
- **보너스 돌:** 특정 확률로 놓은 돌이 보너스 돌(회색)으로 변경될 수 있습니다. 이 돌은 양쪽 플레이어의 돌로 취급되어 연결을 도울 수 있습니다.
- **라인 클리어:** 10개 이상의 돌을 한 줄로 연결하면 해당 라인의 돌들이 제거되고 높은 보너스 점수를 얻습니다.

## 🤖 AI 작동 방식

이 AI는 AlphaZero와 유사한 아키텍처를 사용합니다.

1.  **몬테카를로 트리 탐색 (MCTS):** 현재 상태에서 가능한 여러 수들을 시뮬레이션하여 가장 승률이 높은 수를 탐색합니다.
2.  **정책망 (Policy Network):** 특정 게임 상태에서 어떤 수가 유망한지에 대한 확률 분포를 예측하여 MCTS의 탐색 효율을 높입니다.
3.  **가치망 (Value Network):** 현재 게임 상태가 얼마나 유리한지(승리 확률)를 평가하여 MCTS의 시뮬레이션 결과를 보강합니다.

AI는 셀프 플레이를 통해 생성된 게임 데이터를 바탕으로 정책망과 가치망을 반복적으로 학습하며 기력을 향상시킵니다.

## 📂 프로젝트 구조

```
├── main.py             # AI 모델 학습을 위한 메인 스크립트
├── play.py             # 학습된 AI 모델로 게임을 플레이하는 스크립트
├── triminomok.py       # 트리미노목 게임 로직 구현
├── mcts.py             # 몬테카를로 트리 탐색(MCTS) 알고리즘 구현
├── cnn.py              # 정책망, 가치망 모델(CNN) 정의
├── saves/              # 학습된 모델 가중치 저장 폴더
├── policy_net_*.pth    # 학습된 정책망 모델 파일
├── value_net_*.pth     # 학습된 가치망 모델 파일
├── pyproject.toml      # 프로젝트 설정 및 의존성 관리
└── README.md           # 프로젝트 설명 파일
```

## ⚙️ 요구 사항

- Python >= 3.13
- PyTorch >= 2.7.1
- NumPy >= 2.3.1

의존성 패키지는 다음 명령어로 설치할 수 있습니다.
```bash
pip install -r requirements.txt 
# 또는 pyproject.toml에 명시된 의존성 설치
```
*(현재 `requirements.txt` 파일이 없으므로, `pyproject.toml`을 기반으로 환경을 설정해야 합니다.)*

## 🚀 사용 방법

### 1. AI 모델 학습

`main.py`를 실행하여 AI 학습을 시작합니다. 학습된 모델(`policy_net_*.pth`, `value_net_*.pth`)은 주기적으로 루트 디렉토리와 `saves/` 폴더에 저장됩니다.

```bash
python main.py
```

### 2. AI 대전 관전

`play.py`를 실행하여 학습된 AI가 스스로 대국하는 것을 볼 수 있습니다. 스크립트는 가장 최근에 저장된 모델을 자동으로 불러옵니다.

```bash
python play.py
```

## 📄 라이선스

이 프로젝트는 [MIT 라이선스](LICENSE)를 따릅니다.
